<figure>1</figure>
<caption>Figure 1: An example of a constrained grammar to handle phone deletion. The optional phones are braced by squared brackets [].</caption>
<mention10>"... apply constrained grammars to handle phone deletions as shown in Figure 1. The constrained grammars are based on the phonetic-level canonical ..."</mention10>
<mention20>"... For example, M01 deletes /h/ in the word "house". We apply constrained grammars to handle phone deletions as shown in Figure 1. The constrained grammars are based on the phonetic-level canonical transcriptions, but an optional deletion path is provided for each ..."</mention20>
<mention50>"... with the TORGO non-dysarthric speech training dataset with the HTK scripts published in [10]. Phone deletion is observed in the dysarthric speech of the TORGO corpus as described in [11]. For example, M01 deletes /h/ in the word "house". We apply constrained grammars to handle phone deletions as shown in Figure 1. The constrained grammars are based on the phonetic-level canonical transcriptions, but an optional deletion path is provided for each phone. The current analysis is based on the "real" alignments which do not contain the deleted phones, although the statistics of phone deletion may be useful in future researches. An ..."</mention50>
<lines3> For example, M01 deletes /h/ in the word "house". We apply constrained grammars to handle phone deletions as shown in Figure 1. The constrained grammars are based on the phonetic-level canonical transcriptions, but an optional deletion path is provided for each phone"</lines3>
<lines5> Phone deletion is observed in the dysarthric speech of the TORGO corpus as described in [11]. For example, M01 deletes /h/ in the word "house". We apply constrained grammars to handle phone deletions as shown in Figure 1. The constrained grammars are based on the phonetic-level canonical transcriptions, but an optional deletion path is provided for each phone. The current analysis is based on the "real" alignments which do not contain the deleted phones, although the statistics of phone deletion may be useful in future researches"</lines5>
<snippet3> For example, M01 deletes /h/ in the word "house". We apply constrained grammars to handle phone deletions as shown in Figure 1. The constrained grammars are based on the phonetic-level canonical transcriptions, but an optional deletion path is provided for each phone"</snippet3>
<snippet5> Phone deletion is observed in the dysarthric speech of the TORGO corpus as described in [11]. For example, M01 deletes /h/ in the word "house". We apply constrained grammars to handle phone deletions as shown in Figure 1. The constrained grammars are based on the phonetic-level canonical transcriptions, but an optional deletion path is provided for each phone. The current analysis is based on the "real" alignments which do not contain the deleted phones, although the statistics of phone deletion may be useful in future researches"</snippet5>
<abstract>Imprecise articulatory breakdown is one of the characteristics of dysarthric speech. This work attempts to develop a framework to automatically identify problematic articulatory patterns of dysarthric speakers in terms of distinctive features (DFs), which are effective for describing speech production. The identification of problematic articulatory patterns aims to assist speech therapists in developing intervention strategies. A multilayer perceptron (MLP) system is trained with non-dysarthric speech data for DF recognition. Agreement rates between the recognized DF values and the canonical values based on phonetic transcriptions are computed. For non-dysarthric speech, our system achieves an average agreement rate of 85.7%. The agreement rate of dysarthric speech declines , ranging between 1% to 3% in mild cases, 4% to 7% in moderate cases, and 7% to 12% in severe cases, when compared with non-dysarthric speech. We observe that the DF disagreement patterns are consistent with the analysis of a speech therapist.</abstract>
<title>Analysis of Dysarthric Speech using Distinctive Feature Recognition</title>
<introduction>Dysarthria is a speech disorder caused by disturbances in the muscular control of the speech production mechanism [1]. Stroke, Parkinson's disease, cerebral palsy, amyotrophic lateral sclerosis and others nervous system-related diseases may cause dysarthria. Dysarthria affects millions of adults around the world, especially their effective speech communication in daily life. Speech-related problems include respiration, phonation, articulation and resonance. Symptoms that emerge in speech signals include hoarseness in voice quality, imprecise segmental articulation, excessive nasalization, as well as disordered prosody. All are detrimental to speech intelligibility.Treatment of dysarthria involves perceptual assessment to characterize the problematic articulatory patterns, devise intervention strategies and monitor progress. Speech therapists generally listen carefully to dysarthric speech, possibly multiple times, in order to monitor progress, and such a process is costly. The situation calls for data-driven, computational techniques that analyze the problematic articulatory patterns of dysarthric speakers, in an attempt to assist human efforts in analysis to inform the development of intervention strategies.Articulatory features describe the place and manner of articulation in speech production. They have been well-studied in the context of speech technology development, articulatory feature recognition with multiplayer perceptrons (MLPs) in telephone speech [2], and articulatory feature recognizer for dysarthric speech using neural networks and support vector machines [3]  [4]. In particular, distinctive features (DFs) are a type of articulatory feature that also describe the general characteristics and acoustic consequences of the constrictions within the vocal tract [5]. DF have been shown to be wellidentifiable from speech signals [5]  [6], which motivates us to study the use of DFs in the analysis of dysarthric speech.We aim to identify problematic articulatory patterns of dysarthric speech in terms of DFs. We apply an MLP-based DF recognition system on both dysarthric and non-dysarthric speech data from the TORGO corpus [7]. We compare the DF recognition results between dysarthric and non-dysarthric speech, with the DF reference derived from canonical pronunciations. For dysarthric subjects, we observe that the agreement rates of the DFs corresponding to poor articulation are significantly lower than those of the non-dysarthric subjects. We also note the relationships between the problematic articulatory patterns and the lower agreement rates of the corresponding DFs.In the next section, we discuss the dysarthric corpus used for this study. In Section 3, we describe the development of a DF recognition system and the procedures to utilize the recognition results. In Section 4, we compare the results between manual analysis of the data based on Frenchay Dysarthric Assessment (FDA) [8] and the automatic DF recognition. We conclude our work in Section 5.</introduction>
<file>W15-5115-Figure1-1.png</file>
<figure>2</figure>
<caption>Figure 2: An aligned result for the M01’s utterance. “_” represents missing phones. In [14], the authors reported M01 often omitted the initial /s/ and /h/and such cases are captured in the alignment in this work.</caption>
<mention10>"... An example of dysarthric speech alignment result is shown in Figure 2. Phonemes in languages can be represented in terms of ..."</mention10>
<mention20>"... statistics of phone deletion may be useful in future researches. An example of dysarthric speech alignment result is shown in Figure 2. Phonemes in languages can be represented in terms of a vector of distinctive features (DF) that capture their characteristics ..."</mention20>
<mention50>"... canonical transcriptions, but an optional deletion path is provided for each phone. The current analysis is based on the "real" alignments which do not contain the deleted phones, although the statistics of phone deletion may be useful in future researches. An example of dysarthric speech alignment result is shown in Figure 2. Phonemes in languages can be represented in terms of a vector of distinctive features (DF) that capture their characteristics [6]. DFs include articulator-bound features like high, back, which relate to the tongue. DFs also include articulator-free features, such as tense, which correspond to the level of articulatory movement. We ..."</mention50>
<lines3> The current analysis is based on the "real" alignments which do not contain the deleted phones, although the statistics of phone deletion may be useful in future researches. An example of dysarthric speech alignment result is shown in Figure 2. Phonemes in languages can be represented in terms of a vector of distinctive features (DF) that capture their characteristics [6]"</lines3>
<lines5> The constrained grammars are based on the phonetic-level canonical transcriptions, but an optional deletion path is provided for each phone. The current analysis is based on the "real" alignments which do not contain the deleted phones, although the statistics of phone deletion may be useful in future researches. An example of dysarthric speech alignment result is shown in Figure 2. Phonemes in languages can be represented in terms of a vector of distinctive features (DF) that capture their characteristics [6]. DFs include articulator-bound features like high, back, which relate to the tongue"</lines5>
<snippet3> The current analysis is based on the "real" alignments which do not contain the deleted phones, although the statistics of phone deletion may be useful in future researches. An example of dysarthric speech alignment result is shown in Figure 2. Phonemes in languages can be represented in terms of a vector of distinctive features (DF) that capture their characteristics [6]"</snippet3>
<snippet5> The constrained grammars are based on the phonetic-level canonical transcriptions, but an optional deletion path is provided for each phone. The current analysis is based on the "real" alignments which do not contain the deleted phones, although the statistics of phone deletion may be useful in future researches. An example of dysarthric speech alignment result is shown in Figure 2. Phonemes in languages can be represented in terms of a vector of distinctive features (DF) that capture their characteristics [6]. DFs include articulator-bound features like high, back, which relate to the tongue"</snippet5>
<abstract>Imprecise articulatory breakdown is one of the characteristics of dysarthric speech. This work attempts to develop a framework to automatically identify problematic articulatory patterns of dysarthric speakers in terms of distinctive features (DFs), which are effective for describing speech production. The identification of problematic articulatory patterns aims to assist speech therapists in developing intervention strategies. A multilayer perceptron (MLP) system is trained with non-dysarthric speech data for DF recognition. Agreement rates between the recognized DF values and the canonical values based on phonetic transcriptions are computed. For non-dysarthric speech, our system achieves an average agreement rate of 85.7%. The agreement rate of dysarthric speech declines , ranging between 1% to 3% in mild cases, 4% to 7% in moderate cases, and 7% to 12% in severe cases, when compared with non-dysarthric speech. We observe that the DF disagreement patterns are consistent with the analysis of a speech therapist.</abstract>
<title>Analysis of Dysarthric Speech using Distinctive Feature Recognition</title>
<introduction>Dysarthria is a speech disorder caused by disturbances in the muscular control of the speech production mechanism [1]. Stroke, Parkinson's disease, cerebral palsy, amyotrophic lateral sclerosis and others nervous system-related diseases may cause dysarthria. Dysarthria affects millions of adults around the world, especially their effective speech communication in daily life. Speech-related problems include respiration, phonation, articulation and resonance. Symptoms that emerge in speech signals include hoarseness in voice quality, imprecise segmental articulation, excessive nasalization, as well as disordered prosody. All are detrimental to speech intelligibility.Treatment of dysarthria involves perceptual assessment to characterize the problematic articulatory patterns, devise intervention strategies and monitor progress. Speech therapists generally listen carefully to dysarthric speech, possibly multiple times, in order to monitor progress, and such a process is costly. The situation calls for data-driven, computational techniques that analyze the problematic articulatory patterns of dysarthric speakers, in an attempt to assist human efforts in analysis to inform the development of intervention strategies.Articulatory features describe the place and manner of articulation in speech production. They have been well-studied in the context of speech technology development, articulatory feature recognition with multiplayer perceptrons (MLPs) in telephone speech [2], and articulatory feature recognizer for dysarthric speech using neural networks and support vector machines [3]  [4]. In particular, distinctive features (DFs) are a type of articulatory feature that also describe the general characteristics and acoustic consequences of the constrictions within the vocal tract [5]. DF have been shown to be wellidentifiable from speech signals [5]  [6], which motivates us to study the use of DFs in the analysis of dysarthric speech.We aim to identify problematic articulatory patterns of dysarthric speech in terms of DFs. We apply an MLP-based DF recognition system on both dysarthric and non-dysarthric speech data from the TORGO corpus [7]. We compare the DF recognition results between dysarthric and non-dysarthric speech, with the DF reference derived from canonical pronunciations. For dysarthric subjects, we observe that the agreement rates of the DFs corresponding to poor articulation are significantly lower than those of the non-dysarthric subjects. We also note the relationships between the problematic articulatory patterns and the lower agreement rates of the corresponding DFs.In the next section, we discuss the dysarthric corpus used for this study. In Section 3, we describe the development of a DF recognition system and the procedures to utilize the recognition results. In Section 4, we compare the results between manual analysis of the data based on Frenchay Dysarthric Assessment (FDA) [8] and the automatic DF recognition. We conclude our work in Section 5.</introduction>
<file>W15-5115-Figure2-1.png</file>
<figure>3</figure>
<caption>Figure 3: An example of substitution -- /sh/ /t/. “*” means “don’t care”. The shaded regions represent the outputs that we are interested. “L” and “R” mean labelled and recognized values respectively. “X” shows how the tense value being recognized in two settings. Since the tense value in /sh/ is “*”, we don’t care it being recognized as “*” (a) or “-” (b)</caption>
<mention10>"... oral cavity Continuant [6] Forming of complete closure   Figure 3: An example of substitution --/sh/ /t/. "*" means "don't ...  "+" or "-". The different configurations have different confusion matrices (Figure 3). We choose the two-class configuration (b) as in Figure 3. The DF recognition problem is generally a binary decision ..."</mention10>
<mention20>"... of stop closure The absence or modification of constrictions in oral cavity Continuant [6] Forming of complete closure   Figure 3: An example of substitution --/sh/ /t/. "*" means "don't care". The shaded regions represent the outputs that we are ...  three-class "+", "-" or "don't care", or (b) with two-class "+" or "-". The different configurations have different confusion matrices (Figure 3). We choose the two-class configuration (b) as in Figure 3. The DF recognition problem is generally a binary decision problem as to whether the recognized value matches with the ..."</mention20>
<mention50>"... vowels are more intense, of longer duration and articulated with a greater deviation of the vocal cavity from its rest position then the lax vowels Delayed Release [20] Slow release of stop closure The absence or modification of constrictions in oral cavity Continuant [6] Forming of complete closure   Figure 3: An example of substitution --/sh/ /t/. "*" means "don't care". The shaded regions represent the outputs that we are interested. "L" and "R" mean labelled and recognized values respectively. "X" shows how the tense value being recognized in two settings. Since the tense value in /sh/ is "*", we ...  (12 coefficients + log-energy + Δ + ΔΔ). The feature is normalized as zero mean and unit variance. At the output layer, there are two possible configurations, either (a) with three-class "+", "-" or "don't care", or (b) with two-class "+" or "-". The different configurations have different confusion matrices (Figure 3). We choose the two-class configuration (b) as in Figure 3. The DF recognition problem is generally a binary decision problem as to whether the recognized value matches with the reference value. For a case labeled "don't care", it is irrelevant whether the classifier's output is "+" or "-", because the DF value does not affect the phone's identity. During ..."</mention50>
<lines3> To train a DF recognition system, we start from the nondysarthric speech data from the T1M1T training set. The   Tense vowels are more intense, of longer duration and articulated with a greater deviation of the vocal cavity from its rest position then the lax vowels Delayed Release [20] Slow release of stop closure The absence or modification of constrictions in oral cavity Continuant [6] Forming of complete closure   Figure 3: An example of substitution --/sh/ /t/. "*" means "don't care". ...  At the output layer, there are two possible configurations, either (a) with three-class "+", "-" or "don't care", or (b) with two-class "+" or "-". The different configurations have different confusion matrices (Figure 3). We choose the two-class configuration (b) as in Figure 3. The DF recognition problem is generally a binary decision problem as to whether the recognized value matches with the reference value"</lines3>
<lines5> When DFs are applied for analysis of dysarthric speech, they should be able to help identify the problematic articulatory patterns that can inform the development of intervention strategies. To train a DF recognition system, we start from the nondysarthric speech data from the T1M1T training set. The   Tense vowels are more intense, of longer duration and articulated with a greater deviation of the vocal cavity from its rest position then the lax vowels Delayed Release [20] Slow release of stop closure The absence or modification of constrictions in oral cavity Continuant [6] Forming of complete closure   Figure 3: An example of substitution --/sh/ /t/. "*" means "don't care". The shaded regions represent the outputs that we are interested. ...  The feature is normalized as zero mean and unit variance. At the output layer, there are two possible configurations, either (a) with three-class "+", "-" or "don't care", or (b) with two-class "+" or "-". The different configurations have different confusion matrices (Figure 3). We choose the two-class configuration (b) as in Figure 3. The DF recognition problem is generally a binary decision problem as to whether the recognized value matches with the reference value. For a case labeled "don't care", it is irrelevant whether the classifier's output is "+" or "-", because the DF value does not affect the phone's identity"</lines5>
<snippet3> To train a DF recognition system, we start from the nondysarthric speech data from the T1M1T training set. The   Tense vowels are more intense, of longer duration and articulated with a greater deviation of the vocal cavity from its rest position then the lax vowels Delayed Release [20] Slow release of stop closure The absence or modification of constrictions in oral cavity Continuant [6] Forming of complete closure   Figure 3: An example of substitution --/sh/ /t/. "*" means "don't care".</snippet3>
<snippet5> When DFs are applied for analysis of dysarthric speech, they should be able to help identify the problematic articulatory patterns that can inform the development of intervention strategies. To train a DF recognition system, we start from the nondysarthric speech data from the T1M1T training set. The   Tense vowels are more intense, of longer duration and articulated with a greater deviation of the vocal cavity from its rest position then the lax vowels Delayed Release [20] Slow release of stop closure The absence or modification of constrictions in oral cavity Continuant [6] Forming of complete closure   Figure 3: An example of substitution --/sh/ /t/. "*" means "don't care". The shaded regions represent the outputs that we are interested.</snippet5>
<abstract>Imprecise articulatory breakdown is one of the characteristics of dysarthric speech. This work attempts to develop a framework to automatically identify problematic articulatory patterns of dysarthric speakers in terms of distinctive features (DFs), which are effective for describing speech production. The identification of problematic articulatory patterns aims to assist speech therapists in developing intervention strategies. A multilayer perceptron (MLP) system is trained with non-dysarthric speech data for DF recognition. Agreement rates between the recognized DF values and the canonical values based on phonetic transcriptions are computed. For non-dysarthric speech, our system achieves an average agreement rate of 85.7%. The agreement rate of dysarthric speech declines , ranging between 1% to 3% in mild cases, 4% to 7% in moderate cases, and 7% to 12% in severe cases, when compared with non-dysarthric speech. We observe that the DF disagreement patterns are consistent with the analysis of a speech therapist.</abstract>
<title>Analysis of Dysarthric Speech using Distinctive Feature Recognition</title>
<introduction>Dysarthria is a speech disorder caused by disturbances in the muscular control of the speech production mechanism [1]. Stroke, Parkinson's disease, cerebral palsy, amyotrophic lateral sclerosis and others nervous system-related diseases may cause dysarthria. Dysarthria affects millions of adults around the world, especially their effective speech communication in daily life. Speech-related problems include respiration, phonation, articulation and resonance. Symptoms that emerge in speech signals include hoarseness in voice quality, imprecise segmental articulation, excessive nasalization, as well as disordered prosody. All are detrimental to speech intelligibility.Treatment of dysarthria involves perceptual assessment to characterize the problematic articulatory patterns, devise intervention strategies and monitor progress. Speech therapists generally listen carefully to dysarthric speech, possibly multiple times, in order to monitor progress, and such a process is costly. The situation calls for data-driven, computational techniques that analyze the problematic articulatory patterns of dysarthric speakers, in an attempt to assist human efforts in analysis to inform the development of intervention strategies.Articulatory features describe the place and manner of articulation in speech production. They have been well-studied in the context of speech technology development, articulatory feature recognition with multiplayer perceptrons (MLPs) in telephone speech [2], and articulatory feature recognizer for dysarthric speech using neural networks and support vector machines [3]  [4]. In particular, distinctive features (DFs) are a type of articulatory feature that also describe the general characteristics and acoustic consequences of the constrictions within the vocal tract [5]. DF have been shown to be wellidentifiable from speech signals [5]  [6], which motivates us to study the use of DFs in the analysis of dysarthric speech.We aim to identify problematic articulatory patterns of dysarthric speech in terms of DFs. We apply an MLP-based DF recognition system on both dysarthric and non-dysarthric speech data from the TORGO corpus [7]. We compare the DF recognition results between dysarthric and non-dysarthric speech, with the DF reference derived from canonical pronunciations. For dysarthric subjects, we observe that the agreement rates of the DFs corresponding to poor articulation are significantly lower than those of the non-dysarthric subjects. We also note the relationships between the problematic articulatory patterns and the lower agreement rates of the corresponding DFs.In the next section, we discuss the dysarthric corpus used for this study. In Section 3, we describe the development of a DF recognition system and the procedures to utilize the recognition results. In Section 4, we compare the results between manual analysis of the data based on Frenchay Dysarthric Assessment (FDA) [8] and the automatic DF recognition. We conclude our work in Section 5.</introduction>
<file>W15-5115-Figure3-1.png</file>
<figure>4</figure>
<caption>Figure 4: The agreement rate of each DF between recognized results and canonical DFs.</caption>
<mention10>"... of the start time and end time of a phone. Figure 4 shows the performance of each DF on the TIMIT ...  92% average frame on phonological binary features achieved by [15]. Figure 4 also shows the performance of the adapted DF recognition ...  DF j from all non-dysarthric subjects in TORGO shown in Figure 4, A i,j is the agreement rate of DF j ..."</mention10>
<mention20>"... DF, we only consider the frame situated at the middle of the start time and end time of a phone. Figure 4 shows the performance of each DF on the TIMIT testing set with the TIMIT MLP recognition system. An average ...  DF recognizer is well-trained with non-dysarthric speech, as compared with 92% average frame on phonological binary features achieved by [15]. Figure 4 also shows the performance of the adapted DF recognition system on the TORGO dysarthric and nondysarthric speech data. On ...  DF agreement rate degradation of individual subjects. agreement rate of DF j from all non-dysarthric subjects in TORGO shown in Figure 4, A i,j is the agreement rate of DF j of dysarthric subject i. The average reduction in DF agreement ..."</mention20>
<mention50>"... are not available immediately. We thus interpret the recognized results as the agreement rate between the recognition system and the canonical DF transcriptions. In computing the agreement rate of each DF, we only consider the frame situated at the middle of the start time and end time of a phone. Figure 4 shows the performance of each DF on the TIMIT testing set with the TIMIT MLP recognition system. An average agreement rate of 91.9% suggests that the DF recognizer is well-trained with non-dysarthric speech, as compared with 92% average frame on phonological binary features achieved by [15]. Figure 4 also shows the performance of the adapted DF recognition system on the TORGO dysarthric and nondysarthric speech data. On non-dysarthric speech of the TORGO corpus, the average agreement rate drops to about 85.7%. The slightly lower DF agreement rate of TORGO nondysarthric speech is probably due to occasional pronunciation ...  rate reduction of dysarthric subject i, N is the total number of DFs, T j is the average    Table 3: A comparison of severity and the average DF agreement rate degradation of individual subjects. agreement rate of DF j from all non-dysarthric subjects in TORGO shown in Figure 4, A i,j is the agreement rate of DF j of dysarthric subject i. The average reduction in DF agreement rates, D i , is shown in Table 3. More severely dysarthric subjects have larger agreement rate reduction. A speech therapist has evaluated the severity of the dysarthric subjects in ..."</mention50>
<lines3> 1n computing the agreement rate of each DF, we only consider the frame situated at the middle of the start time and end time of a phone. Figure 4 shows the performance of each DF on the T1M1T testing set with the T1M1T MLP recognition system. An average agreement rate of 91.9% suggests that the DF recognizer is well-trained with non-dysarthric speech, as compared with 92% average frame on phonological binary features achieved by [15]. Figure 4 also shows the performance of the adapted DF recognition system on the TORGO dysarthric and nondysarthric speech data. On non-dysarthric speech of the TORGO corpus, the average agreement rate drops to about 85.7%. ...  The average reduction in agreement rates of each dysarthric subject is calculated by equation (1) where D i is the average agreement rate reduction of dysarthric subject i, N is the total number of DFs, T j is the average    Table 3: A comparison of severity and the average DF agreement rate degradation of individual subjects. agreement rate of DF j from all non-dysarthric subjects in TORGO shown in Figure 4, A i,j is the agreement rate of DF j of dysarthric subject i. The average reduction in DF agreement rates, D i , is shown in Table 3"</lines3>
<lines5> We thus interpret the recognized results as the agreement rate between the recognition system and the canonical DF transcriptions. 1n computing the agreement rate of each DF, we only consider the frame situated at the middle of the start time and end time of a phone. Figure 4 shows the performance of each DF on the T1M1T testing set with the T1M1T MLP recognition system. An average agreement rate of 91.9% suggests that the DF recognizer is well-trained with non-dysarthric speech, as compared with 92% average frame on phonological binary features achieved by [15]. Figure 4 also shows the performance of the adapted DF recognition system on the TORGO dysarthric and nondysarthric speech data. On non-dysarthric speech of the TORGO corpus, the average agreement rate drops to about 85.7%. The slightly lower DF agreement rate of TORGO nondysarthric speech is probably due to occasional pronunciation variation from canonical pronunciations. ...  The severity of each dysarthric subject is reported in [11]. The average reduction in agreement rates of each dysarthric subject is calculated by equation (1) where D i is the average agreement rate reduction of dysarthric subject i, N is the total number of DFs, T j is the average    Table 3: A comparison of severity and the average DF agreement rate degradation of individual subjects. agreement rate of DF j from all non-dysarthric subjects in TORGO shown in Figure 4, A i,j is the agreement rate of DF j of dysarthric subject i. The average reduction in DF agreement rates, D i , is shown in Table 3. More severely dysarthric subjects have larger agreement rate reduction"</lines5>
<snippet3> 1n computing the agreement rate of each DF, we only consider the frame situated at the middle of the start time and end time of a phone. Figure 4 shows the performance of each DF on the T1M1T testing set with the T1M1T MLP recognition system. An average agreement rate of 91.9% suggests that the DF recognizer is well-trained with non-dysarthric speech, as compared with 92% average frame on phonological binary features achieved by [15]. Figure 4 also shows the performance of the adapted DF recognition system on the TORGO dysarthric and nondysarthric speech data. On non-dysarthric speech of the TORGO corpus, the average agreement rate drops to about 85.7%.</snippet3>
<snippet5> We thus interpret the recognized results as the agreement rate between the recognition system and the canonical DF transcriptions. 1n computing the agreement rate of each DF, we only consider the frame situated at the middle of the start time and end time of a phone. Figure 4 shows the performance of each DF on the T1M1T testing set with the T1M1T MLP recognition system. An average agreement rate of 91.9% suggests that the DF recognizer is well-trained with non-dysarthric speech, as compared with 92% average frame on phonological binary features achieved by [15]. Figure 4 also shows the performance of the adapted DF recognition system on the TORGO dysarthric and nondysarthric speech data. On non-dysarthric speech of the TORGO corpus, the average agreement rate drops to about 85.7%. The slightly lower DF agreement rate of TORGO nondysarthric speech is probably due to occasional pronunciation variation from canonical pronunciations.</snippet5>
<abstract>Imprecise articulatory breakdown is one of the characteristics of dysarthric speech. This work attempts to develop a framework to automatically identify problematic articulatory patterns of dysarthric speakers in terms of distinctive features (DFs), which are effective for describing speech production. The identification of problematic articulatory patterns aims to assist speech therapists in developing intervention strategies. A multilayer perceptron (MLP) system is trained with non-dysarthric speech data for DF recognition. Agreement rates between the recognized DF values and the canonical values based on phonetic transcriptions are computed. For non-dysarthric speech, our system achieves an average agreement rate of 85.7%. The agreement rate of dysarthric speech declines , ranging between 1% to 3% in mild cases, 4% to 7% in moderate cases, and 7% to 12% in severe cases, when compared with non-dysarthric speech. We observe that the DF disagreement patterns are consistent with the analysis of a speech therapist.</abstract>
<title>Analysis of Dysarthric Speech using Distinctive Feature Recognition</title>
<introduction>Dysarthria is a speech disorder caused by disturbances in the muscular control of the speech production mechanism [1]. Stroke, Parkinson's disease, cerebral palsy, amyotrophic lateral sclerosis and others nervous system-related diseases may cause dysarthria. Dysarthria affects millions of adults around the world, especially their effective speech communication in daily life. Speech-related problems include respiration, phonation, articulation and resonance. Symptoms that emerge in speech signals include hoarseness in voice quality, imprecise segmental articulation, excessive nasalization, as well as disordered prosody. All are detrimental to speech intelligibility.Treatment of dysarthria involves perceptual assessment to characterize the problematic articulatory patterns, devise intervention strategies and monitor progress. Speech therapists generally listen carefully to dysarthric speech, possibly multiple times, in order to monitor progress, and such a process is costly. The situation calls for data-driven, computational techniques that analyze the problematic articulatory patterns of dysarthric speakers, in an attempt to assist human efforts in analysis to inform the development of intervention strategies.Articulatory features describe the place and manner of articulation in speech production. They have been well-studied in the context of speech technology development, articulatory feature recognition with multiplayer perceptrons (MLPs) in telephone speech [2], and articulatory feature recognizer for dysarthric speech using neural networks and support vector machines [3]  [4]. In particular, distinctive features (DFs) are a type of articulatory feature that also describe the general characteristics and acoustic consequences of the constrictions within the vocal tract [5]. DF have been shown to be wellidentifiable from speech signals [5]  [6], which motivates us to study the use of DFs in the analysis of dysarthric speech.We aim to identify problematic articulatory patterns of dysarthric speech in terms of DFs. We apply an MLP-based DF recognition system on both dysarthric and non-dysarthric speech data from the TORGO corpus [7]. We compare the DF recognition results between dysarthric and non-dysarthric speech, with the DF reference derived from canonical pronunciations. For dysarthric subjects, we observe that the agreement rates of the DFs corresponding to poor articulation are significantly lower than those of the non-dysarthric subjects. We also note the relationships between the problematic articulatory patterns and the lower agreement rates of the corresponding DFs.In the next section, we discuss the dysarthric corpus used for this study. In Section 3, we describe the development of a DF recognition system and the procedures to utilize the recognition results. In Section 4, we compare the results between manual analysis of the data based on Frenchay Dysarthric Assessment (FDA) [8] and the automatic DF recognition. We conclude our work in Section 5.</introduction>
<file>W15-5115-Figure4-1.png</file>
<figure>5</figure>
<caption>Figure 5: The difference between the average DF agreement rate from the control subjects and the corresponding DF agreement rate of each dysarthric subject. The agreement rates of most of the DF drop substainally for severely dysarthric subjects. The agreement rates in moderately and mildly dysarthric subjects only dropped in a few DFs.</caption>
<mention10>"... and identified the pronunciation error patterns of the individual subjects. Figure 5 shows the drop in DF agreement rates for two ...  Continuant relates to the production of /f/ ("+", no com- Figure 5: The difference between the average DF agreement rate from ..."</mention10>
<mention20>"... studied 25% of the speech data of each dysarthric subject and identified the pronunciation error patterns of the individual subjects. Figure 5 shows the drop in DF agreement rates for two severely dysarthric subjects (F01 and M04), one moderately dysarthric subject ...  and strident. The trend is consistent with other consonant-related DFs. Continuant relates to the production of /f/ ("+", no com- Figure 5: The difference between the average DF agreement rate from the control subjects and the corresponding DF agreement rate of ..."</mention20>
<mention50>"... severity of the dysarthric subjects on different articulatory dimensions. We validate the recognized DF error patterns to the FDA results and the manual analysis from [11]. In [11], the authors studied 25% of the speech data of each dysarthric subject and identified the pronunciation error patterns of the individual subjects. Figure 5 shows the drop in DF agreement rates for two severely dysarthric subjects (F01 and M04), one moderately dysarthric subject (F03), one mildly dysarthric subject (M03) and two non-dysarthric subjects (FC02 and MC04) for comparison to illustrate the relationship among the error patterns and agreement rates. FC02's pronunciation is slightly ...  with the speech therapist's findings that their voice production is inappropriate and ineffective in most situations. For articulator-free DFs, the dysarthric subjects generally exhibit lower agreement rates on consonantal, continuant and strident. The trend is consistent with other consonant-related DFs. Continuant relates to the production of /f/ ("+", no com- Figure 5: The difference between the average DF agreement rate from the control subjects and the corresponding DF agreement rate of each dysarthric subject. The agreement rates of most of the DF drop substainally for severely dysarthric subjects. The agreement rates in moderately and mildly dysarthric subjects only dropped in a ..."</mention50>
<lines3> 1n [11], the authors studied 25% of the speech data of each dysarthric subject and identified the pronunciation error patterns of the individual subjects. Figure 5 shows the drop in DF agreement rates for two severely dysarthric subjects (F01 and M04), one moderately dysarthric subject (F03), one mildly dysarthric subject (M03) and two non-dysarthric subjects (FC02 and MC04) for comparison to illustrate the relationship among the error patterns and agreement rates. FC02's pronunciation is slightly better than that of MC04. ...  The trend is consistent with other consonant-related DFs. Continuant relates to the production of /f/ ("+", no com- Figure 5: The difference between the average DF agreement rate from the control subjects and the corresponding DF agreement rate of each dysarthric subject. The agreement rates of most of the DF drop substainally for severely dysarthric subjects"</lines3>
<lines5> We validate the recognized DF error patterns to the FDA results and the manual analysis from [11]. 1n [11], the authors studied 25% of the speech data of each dysarthric subject and identified the pronunciation error patterns of the individual subjects. Figure 5 shows the drop in DF agreement rates for two severely dysarthric subjects (F01 and M04), one moderately dysarthric subject (F03), one mildly dysarthric subject (M03) and two non-dysarthric subjects (FC02 and MC04) for comparison to illustrate the relationship among the error patterns and agreement rates. FC02's pronunciation is slightly better than that of MC04. For the tongue-related DFs, F01 exhibits substantial drops in agreement rates on anterior, alveolar and velar. ...  For articulator-free DFs, the dysarthric subjects generally exhibit lower agreement rates on consonantal, continuant and strident. The trend is consistent with other consonant-related DFs. Continuant relates to the production of /f/ ("+", no com- Figure 5: The difference between the average DF agreement rate from the control subjects and the corresponding DF agreement rate of each dysarthric subject. The agreement rates of most of the DF drop substainally for severely dysarthric subjects. The agreement rates in moderately and mildly dysarthric subjects only dropped in a few DFs"</lines5>
<snippet3> 1n [11], the authors studied 25% of the speech data of each dysarthric subject and identified the pronunciation error patterns of the individual subjects. Figure 5 shows the drop in DF agreement rates for two severely dysarthric subjects (F01 and M04), one moderately dysarthric subject (F03), one mildly dysarthric subject (M03) and two non-dysarthric subjects (FC02 and MC04) for comparison to illustrate the relationship among the error patterns and agreement rates. FC02's pronunciation is slightly better than that of MC04.</snippet3>
<snippet5> We validate the recognized DF error patterns to the FDA results and the manual analysis from [11]. 1n [11], the authors studied 25% of the speech data of each dysarthric subject and identified the pronunciation error patterns of the individual subjects. Figure 5 shows the drop in DF agreement rates for two severely dysarthric subjects (F01 and M04), one moderately dysarthric subject (F03), one mildly dysarthric subject (M03) and two non-dysarthric subjects (FC02 and MC04) for comparison to illustrate the relationship among the error patterns and agreement rates. FC02's pronunciation is slightly better than that of MC04. For the tongue-related DFs, F01 exhibits substantial drops in agreement rates on anterior, alveolar and velar.</snippet5>
<abstract>Imprecise articulatory breakdown is one of the characteristics of dysarthric speech. This work attempts to develop a framework to automatically identify problematic articulatory patterns of dysarthric speakers in terms of distinctive features (DFs), which are effective for describing speech production. The identification of problematic articulatory patterns aims to assist speech therapists in developing intervention strategies. A multilayer perceptron (MLP) system is trained with non-dysarthric speech data for DF recognition. Agreement rates between the recognized DF values and the canonical values based on phonetic transcriptions are computed. For non-dysarthric speech, our system achieves an average agreement rate of 85.7%. The agreement rate of dysarthric speech declines , ranging between 1% to 3% in mild cases, 4% to 7% in moderate cases, and 7% to 12% in severe cases, when compared with non-dysarthric speech. We observe that the DF disagreement patterns are consistent with the analysis of a speech therapist.</abstract>
<title>Analysis of Dysarthric Speech using Distinctive Feature Recognition</title>
<introduction>Dysarthria is a speech disorder caused by disturbances in the muscular control of the speech production mechanism [1]. Stroke, Parkinson's disease, cerebral palsy, amyotrophic lateral sclerosis and others nervous system-related diseases may cause dysarthria. Dysarthria affects millions of adults around the world, especially their effective speech communication in daily life. Speech-related problems include respiration, phonation, articulation and resonance. Symptoms that emerge in speech signals include hoarseness in voice quality, imprecise segmental articulation, excessive nasalization, as well as disordered prosody. All are detrimental to speech intelligibility.Treatment of dysarthria involves perceptual assessment to characterize the problematic articulatory patterns, devise intervention strategies and monitor progress. Speech therapists generally listen carefully to dysarthric speech, possibly multiple times, in order to monitor progress, and such a process is costly. The situation calls for data-driven, computational techniques that analyze the problematic articulatory patterns of dysarthric speakers, in an attempt to assist human efforts in analysis to inform the development of intervention strategies.Articulatory features describe the place and manner of articulation in speech production. They have been well-studied in the context of speech technology development, articulatory feature recognition with multiplayer perceptrons (MLPs) in telephone speech [2], and articulatory feature recognizer for dysarthric speech using neural networks and support vector machines [3]  [4]. In particular, distinctive features (DFs) are a type of articulatory feature that also describe the general characteristics and acoustic consequences of the constrictions within the vocal tract [5]. DF have been shown to be wellidentifiable from speech signals [5]  [6], which motivates us to study the use of DFs in the analysis of dysarthric speech.We aim to identify problematic articulatory patterns of dysarthric speech in terms of DFs. We apply an MLP-based DF recognition system on both dysarthric and non-dysarthric speech data from the TORGO corpus [7]. We compare the DF recognition results between dysarthric and non-dysarthric speech, with the DF reference derived from canonical pronunciations. For dysarthric subjects, we observe that the agreement rates of the DFs corresponding to poor articulation are significantly lower than those of the non-dysarthric subjects. We also note the relationships between the problematic articulatory patterns and the lower agreement rates of the corresponding DFs.In the next section, we discuss the dysarthric corpus used for this study. In Section 3, we describe the development of a DF recognition system and the procedures to utilize the recognition results. In Section 4, we compare the results between manual analysis of the data based on Frenchay Dysarthric Assessment (FDA) [8] and the automatic DF recognition. We conclude our work in Section 5.</introduction>
<file>W15-5115-Figure5-1.png</file>
